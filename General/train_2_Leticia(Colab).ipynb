{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86037f9",
   "metadata": {},
   "source": [
    "# Entrenamiento Modelo - ResNet18 + Metadatos \n",
    "Este notebook entrena un modelo **multiclase** con imágenes 224×224 + metadatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comprobar GPU y entorno\n",
    "import torch, sys\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instalar dependencias\n",
    "!pip -q install mlflow charset-normalizer pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/ProyectoFinalKC\"\n",
    "import os, pathlib\n",
    "pathlib.Path(PROJECT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(\"Working dir:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estructura de carpetas esperada\n",
    "import os, pathlib\n",
    "pathlib.Path(\"General\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(\"Data/dataset\").mkdir(parents=True, exist_ok=True)\n",
    "print(\"Estructura creada/chequeada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports y configuración\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import mlflow, tempfile, shutil\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(str(Path(\"General\").resolve()))\n",
    "from load_dataloaders_Leti import load_dataloaders\n",
    "\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "DATA_DIR = BASE_DIR / \"Data\" / \"dataset\"\n",
    "TRAIN_PT = str(DATA_DIR / \"train_dataset.pt\")\n",
    "VAL_PT   = str(DATA_DIR / \"val_dataset.pt\")\n",
    "TEST_PT  = str(DATA_DIR / \"test_dataset.pt\")\n",
    "\n",
    "BATCH_SIZE   = 64\n",
    "EPOCHS       = 20\n",
    "LR           = 1e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "NUM_WORKERS  = 2\n",
    "SEED         = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pin_mem = device.type == \"cuda\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dac340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def get_train_transform(img_size: int = 224):\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std =[0.229, 0.224, 0.225]),\n",
    "        T.RandomErasing(p=0.1)\n",
    "    ])\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# Cargar DataLoaders desde tus Subsets .pt\n",
    "train_loader, val_loader, test_loader = load_dataloaders(\n",
    "    TRAIN_PT, VAL_PT, TEST_PT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin_mem,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Sobrescribir transform SOLO para train\n",
    "base_train_ds = train_loader.dataset.dataset  \n",
    "base_train_ds.transform = get_train_transform(224)\n",
    "print(\"Transform de train aplicada:\", base_train_ds.transform)\n",
    "\n",
    "# Inferir meta_dim, num_classes y class weights\n",
    "train_subset = train_loader.dataset\n",
    "sample = train_subset[0]\n",
    "meta_dim = int(sample[1].shape[0])\n",
    "\n",
    "def get_train_labels(train_subset):\n",
    "    base = train_subset.dataset\n",
    "    idxs = train_subset.indices\n",
    "    import numpy as np\n",
    "    return np.array([int(base.targets[i]) for i in idxs], dtype=int)\n",
    "\n",
    "y_train = get_train_labels(train_subset)\n",
    "\n",
    "num_classes = int(y_train.max() + 1)\n",
    "class_names = [str(i) for i in range(num_classes)]\n",
    "\n",
    "def compute_class_weights(y, num_classes):\n",
    "    import numpy as np, torch\n",
    "    counts = np.bincount(y, minlength=num_classes).astype(np.float64)\n",
    "    w = 1.0 / (counts + 1e-6)\n",
    "    w = w * (num_classes / w.sum())\n",
    "    return torch.tensor(w, dtype=torch.float32)\n",
    "\n",
    "class_weights = compute_class_weights(y_train, num_classes).to(device)\n",
    "\n",
    "print(f\"num_classes={num_classes}, meta_dim={meta_dim}, train_size={len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelo (ResNet18 + MLP metadatos)\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, meta_dim: int, num_classes: int, pretrained: bool = True, dropout: float = 0.6):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        self.backbone = resnet18(weights=weights)\n",
    "        in_feats = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.meta = nn.Sequential(\n",
    "            nn.Linear(meta_dim, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_feats + 32, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_meta):\n",
    "        f_img = self.backbone(x_img)\n",
    "        f_meta = self.meta(x_meta)\n",
    "        f = torch.cat([f_img, f_meta], dim=1)\n",
    "        return self.head(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo + criterio + optimizador\n",
    "model = ImageClassifier(meta_dim=meta_dim, num_classes=num_classes, pretrained=True, dropout=0.6).to(device)\n",
    "\n",
    "# Regularización: class weights + label smoothing\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.10)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de train/eval con métricas (acc, F1, precision, recall)\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_confusion(cm, class_names, out_path: Path):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Matriz de confusión\"); plt.colorbar()\n",
    "    ticks = range(len(class_names))\n",
    "    plt.xticks(ticks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, class_names)\n",
    "    plt.tight_layout(); plt.ylabel(\"Real\"); plt.xlabel(\"Predicción\")\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    ys_all, ps_all = [], []\n",
    "    for imgs, metas, ys in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        metas = metas.to(device, non_blocking=True)\n",
    "        ys   = ys.to(device, non_blocking=True, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "            logits = model(imgs, metas)\n",
    "            loss   = criterion(logits, ys)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        ys_all.append(ys.detach().cpu()); ps_all.append(preds.detach().cpu())\n",
    "\n",
    "    loss_ep = total_loss / len(loader.dataset)\n",
    "    y = torch.cat(ys_all).numpy(); p = torch.cat(ps_all).numpy()\n",
    "    acc = accuracy_score(y, p); f1m = f1_score(y, p, average=\"macro\")\n",
    "    return loss_ep, acc, f1m\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device, prefix, class_names, out_dir: Path):\n",
    "    model.eval()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    ys_all, ps_all = [], []\n",
    "    for imgs, metas, ys in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        metas = metas.to(device, non_blocking=True)\n",
    "        ys   = ys.to(device, non_blocking=True, dtype=torch.long)\n",
    "        logits = model(imgs, metas)\n",
    "        loss = criterion(logits, ys)\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        ys_all.append(ys.detach().cpu()); ps_all.append(preds.detach().cpu())\n",
    "\n",
    "    loss_ep = total_loss / len(loader.dataset)\n",
    "    y = torch.cat(ys_all).numpy(); p = torch.cat(ps_all).numpy()\n",
    "    acc   = accuracy_score(y, p)\n",
    "    f1m   = f1_score(y, p, average=\"macro\")\n",
    "    precm = precision_score(y, p, average=\"macro\", zero_division=0)\n",
    "    recm  = recall_score(y, p, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # Artefactos (report + cm)\n",
    "    rep_path = out_dir / f\"{prefix}_classification_report.txt\"\n",
    "    with open(rep_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(classification_report(y, p, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(y, p)\n",
    "    cm_path = out_dir / f\"{prefix}_confusion_matrix.png\"\n",
    "    plot_confusion(cm, class_names, cm_path)\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss_ep, \"acc\": acc, \"f1_macro\": f1m,\n",
    "        \"precision_macro\": precm, \"recall_macro\": recm,\n",
    "        \"rep_path\": str(rep_path), \"cm_path\": str(cm_path)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow: setup y logging\n",
    "mlruns_dir = Path.cwd() / \"mlruns\"             \n",
    "mlflow.set_tracking_uri(\"file:\" + str(mlruns_dir.resolve()))\n",
    "mlflow.set_experiment(\"Experimento_Leticia_ResNet18_Colab\")\n",
    "\n",
    "RUN_NAME = \"colab_resnet18_mm_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "mlflow.start_run(run_name=RUN_NAME)\n",
    "mlflow.log_params({\n",
    "    \"batch_size\": BATCH_SIZE, \"epochs\": EPOCHS,\n",
    "    \"lr\": LR, \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"num_workers\": NUM_WORKERS, \"pin_memory\": pin_mem,\n",
    "    \"label_smoothing\": 0.10,\n",
    "    \"meta_dim\": meta_dim, \"num_classes\": num_classes,\n",
    "    \"backbone\": \"resnet18_imagenet\", \"dropout\": 0.6,\n",
    "})\n",
    "\n",
    "# Carpeta temporal para artefactos (se suben a MLflow y se borran)\n",
    "tmp_art_dir = Path(tempfile.mkdtemp(prefix=\"mlflow_artifacts_\"))\n",
    "tmp_art_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba97be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop con early stopping y logging a MLflow\n",
    "best_val_f1 = -1.0\n",
    "patience = 6\n",
    "bad = 0\n",
    "\n",
    "ckpt_path = tmp_art_dir / \"best_model.pt\"  # se subirá a MLflow al mejorar\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc, tr_f1m = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    va_out = evaluate(model, val_loader, criterion, device, prefix=\"val\",\n",
    "                      class_names=class_names, out_dir=tmp_art_dir / \"reports_val\")\n",
    "\n",
    "    print(f\"[Época {epoch:02d}/{EPOCHS}] \"\n",
    "          f\"train_loss={tr_loss:.4f} acc={tr_acc:.4f} f1m={tr_f1m:.4f} | \"\n",
    "          f\"val_loss={va_out['loss']:.4f} acc={va_out['acc']:.4f} f1m={va_out['f1_macro']:.4f}\")\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": tr_loss, \"train_acc\": tr_acc, \"train_f1m\": tr_f1m,\n",
    "        \"val_loss\": va_out[\"loss\"], \"val_acc\": va_out[\"acc\"], \"val_f1m\": va_out[\"f1_macro\"],\n",
    "        \"val_prec_m\": va_out[\"precision_macro\"], \"val_rec_m\": va_out[\"recall_macro\"],\n",
    "    }, step=epoch)\n",
    "\n",
    "    # Guardar mejor\n",
    "    if va_out[\"f1_macro\"] > best_val_f1 + 1e-6:\n",
    "        best_val_f1 = va_out[\"f1_macro\"]; bad = 0\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        # Subir a MLflow artefactos de val\n",
    "        mlflow.log_artifact(str(ckpt_path))\n",
    "        mlflow.log_artifact(va_out[\"rep_path\"])\n",
    "        mlflow.log_artifact(va_out[\"cm_path\"])\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test final + cierre de MLflow\n",
    "# Cargar mejor modelo si existe\n",
    "if ckpt_path.exists():\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=\"cpu\"))\n",
    "    model.to(device)\n",
    "\n",
    "# En test quitamos smoothing pero mantenemos class weights\n",
    "criterion_eval = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "test_out = evaluate(model, test_loader, criterion_eval, device, prefix=\"test\",\n",
    "                    class_names=class_names, out_dir=tmp_art_dir / \"reports_test\")\n",
    "\n",
    "print(f\"[TEST] loss={test_out['loss']:.4f} acc={test_out['acc']:.4f} f1m={test_out['f1_macro']:.4f}\")\n",
    "\n",
    "# Log a MLflow\n",
    "mlflow.log_metrics({\n",
    "    \"test_loss\":   test_out[\"loss\"],\n",
    "    \"test_acc\":    test_out[\"acc\"],\n",
    "    \"test_f1m\":    test_out[\"f1_macro\"],\n",
    "    \"test_prec_m\": test_out[\"precision_macro\"],\n",
    "    \"test_rec_m\":  test_out[\"recall_macro\"],\n",
    "})\n",
    "\n",
    "mlflow.log_artifact(test_out[\"rep_path\"])\n",
    "mlflow.log_artifact(test_out[\"cm_path\"])\n",
    "\n",
    "# Limpieza local y cierre del run\n",
    "shutil.rmtree(tmp_art_dir, ignore_errors=True)\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"Artefactos y métricas guardados en:\", mlruns_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
