{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64903623",
   "metadata": {},
   "source": [
    "# Entrenamiento_3 modelo Multiclase con ResNet18 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c805f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install mlflow scikit-learn matplotlib pillow pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e4bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18 (main, Jun  5 2025, 08:13:51) [Clang 14.0.6 ]\n",
      "PyTorch: 1.13.1\n",
      "CUDA disponible: False\n"
     ]
    }
   ],
   "source": [
    "# Comprobar GPU y entorno\n",
    "import torch, sys\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd03630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Google Drive\n",
    "import os, pathlib\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/ProyectoFinalKC\"\n",
    "pathlib.Path(PROJECT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(\"Working dir:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdeceb4",
   "metadata": {},
   "source": [
    "## Guardar quality_df (parquet + csv) en Data/quality_df/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6eacf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No está quality_df en memoria o faltan columnas: ['filename', 'brightness', 'contrast', 'is_dark', 'is_bright', 'is_low_contrast', 'is_high_contrast']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_df\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m quality_df\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo está quality_df en memoria o faltan columnas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m quality_df \u001b[38;5;241m=\u001b[39m quality_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     12\u001b[0m quality_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m quality_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No está quality_df en memoria o faltan columnas: ['filename', 'brightness', 'contrast', 'is_dark', 'is_bright', 'is_low_contrast', 'is_high_contrast']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Verificación mínima\n",
    "required_cols = [\"filename\", \"brightness\", \"contrast\",\n",
    "                 \"is_dark\", \"is_bright\", \"is_low_contrast\", \"is_high_contrast\"]\n",
    "missing = [c for c in required_cols if 'quality_df' not in globals() or c not in quality_df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"No está quality_df en memoria o faltan columnas: {missing}\")\n",
    "\n",
    "quality_df = quality_df.copy()\n",
    "quality_df[\"filename\"] = quality_df[\"filename\"].astype(str)\n",
    "\n",
    "# Guardamos lo esencial (flags + métricas básicas)\n",
    "q_keep = [\"filename\", \"brightness\", \"contrast\", \"is_dark\", \"is_low_contrast\"]\n",
    "quality_min = quality_df[q_keep].drop_duplicates(subset=\"filename\")\n",
    "\n",
    "out_dir = Path(\"Data/quality_df\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "pq_path  = out_dir / \"quality_df.parquet\"\n",
    "csv_path = out_dir / \"quality_df.csv\"\n",
    "\n",
    "quality_min.to_parquet(pq_path, index=False)\n",
    "quality_min.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"Guardado quality_df en:\")\n",
    "print(\" -\", pq_path)\n",
    "print(\" -\", csv_path)\n",
    "print(\"Filas:\", len(quality_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bd075",
   "metadata": {},
   "source": [
    "## Unir flags de calidad al parquet base → dataset_meta_ojouni_quality.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d37e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = Path(\"Data/parquet/dataset_meta_ojouni.parquet\")\n",
    "q_path    = Path(\"Data/quality_df/quality_df.parquet\")\n",
    "\n",
    "meta = pd.read_parquet(meta_path).reset_index(drop=True)\n",
    "qdf  = pd.read_parquet(q_path).reset_index(drop=True)\n",
    "\n",
    "meta[\"filename\"] = meta[\"filename\"].astype(str)\n",
    "qdf[\"filename\"]  = qdf[\"filename\"].astype(str)\n",
    "\n",
    "# Seleccionamos los flags de calidad (una fila por imagen)\n",
    "q_flags = qdf[[\"filename\", \"is_dark\", \"is_low_contrast\"]].drop_duplicates(subset=\"filename\")\n",
    "\n",
    "merged = meta.merge(q_flags, on=\"filename\", how=\"left\", validate=\"one_to_one\")\n",
    "\n",
    "# Relleno seguro (si alguna imagen no está en quality_df)\n",
    "for c in [\"is_dark\", \"is_low_contrast\"]:\n",
    "    if c not in merged.columns:\n",
    "        merged[c] = False\n",
    "    merged[c] = merged[c].fillna(False).astype(bool)\n",
    "\n",
    "out_meta = Path(\"Data/parquet/dataset_meta_ojouni_quality.parquet\")\n",
    "merged.to_parquet(out_meta, index=False)\n",
    "\n",
    "print(\"Parquet enriquecido guardado en:\", out_meta)\n",
    "print(\"is_dark True %:\", round(merged[\"is_dark\"].mean()*100, 2))\n",
    "print(\"is_low_contrast True %:\", round(merged[\"is_low_contrast\"].mean()*100, 2))\n",
    "print(\"Filas:\", len(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para confirmar si hy fugas de pacientes entre splits!!!!!!!!!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"Data/parquet/dataset_meta_ojouni_quality.parquet\").reset_index(drop=True)\n",
    "# Extrae un ID de paciente del filename (ajusta si tu patrón difiere)\n",
    "df[\"patient_id\"] = df[\"filename\"].str.extract(r\"^(\\d+)_\").astype(str)\n",
    "\n",
    "train_p = set(df.loc[tr_idx, \"patient_id\"])\n",
    "val_p   = set(df.loc[va_idx, \"patient_id\"])\n",
    "test_p  = set(df.loc[te_idx, \"patient_id\"])\n",
    "\n",
    "print(\"Pacientes solapados train↔val:\", len(train_p & val_p))\n",
    "print(\"Pacientes solapados train↔test:\", len(train_p & test_p))\n",
    "print(\"Pacientes solapados val↔test:\", len(val_p & test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el script que construye los .pt (subsets) en Data/dataset/\n",
    "RUTA_CREATE = \"General/create_split_dataset_Leti.py\"  \n",
    "assert os.path.exists(RUTA_CREATE), f\"No se encuentra el script: {RUTA_CREATE}\"\n",
    "!python -u {RUTA_CREATE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"Data\", \"dataset\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "esperados = [\"train_dataset.pt\", \"val_dataset.pt\", \"test_dataset.pt\"]\n",
    "print(\"Data/dataset:\", os.listdir(data_dir) if os.path.isdir(data_dir) else \"No existe\")\n",
    "\n",
    "faltan = [f for f in esperados if not os.path.exists(os.path.join(data_dir, f))]\n",
    "assert not faltan, f\"FALTAN archivos en Data/dataset: {faltan}\"\n",
    "print(\"Subsets OK:\", esperados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar script real de entrenamiento\n",
    "RUTA_SCRIPT = \"General/train_3_Leticia.py\"  \n",
    "assert os.path.exists(RUTA_SCRIPT), f\"No se encuentra el script: {RUTA_SCRIPT}\"\n",
    "\n",
    "# Ejecutar el entrenamiento (tu script ya configura MLflow y guarda artefactos en mlruns)\n",
    "!python -u {RUTA_SCRIPT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
